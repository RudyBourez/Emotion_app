{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe = pd.read_csv(\"../Data/Data_cleaned/emotion_cleaned_rudy.csv\")[[\"target\", \"clean_text\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "dfe[\"cible\"] = encoder.fit_transform(dfe[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dfe[\"clean_text\"], dfe[\"cible\"], train_size=0.8, random_state=1, stratify=dfe[\"target\"])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.5, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer =CountVectorizer()\n",
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = vectorizer.transform(X_train)\n",
    "X_test_t = vectorizer.transform(X_test)\n",
    "X_val_t = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "initializer = keras.initializers.HeNormal()\n",
    "regularizer = keras.regularizers.L2(0.005)\n",
    "\n",
    "model.add(keras.layers.Dense(64, input_dim=X_train_t.shape[1], activation=\"relu\",\n",
    "                             kernel_initializer=initializer,kernel_regularizer=regularizer))\n",
    "model.add(keras.layers.AlphaDropout(20))\n",
    "model.add(keras.layers.Dense(32, input_dim=X_train_t.shape[1],kernel_regularizer=regularizer, activation=\"relu\"))\n",
    "model.add(keras.layers.AlphaDropout(20))\n",
    "model.add(keras.layers.Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss= keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer= keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1073/1073 [==============================] - 10s 9ms/step - loss: 1.2457 - accuracy: 0.7723 - val_loss: 1.2179 - val_accuracy: 0.7969\n",
      "Epoch 2/100\n",
      "1073/1073 [==============================] - 10s 9ms/step - loss: 1.0594 - accuracy: 0.8429 - val_loss: 1.1382 - val_accuracy: 0.8218\n",
      "Epoch 3/100\n",
      "1073/1073 [==============================] - 9s 9ms/step - loss: 0.9783 - accuracy: 0.8656 - val_loss: 1.0961 - val_accuracy: 0.8243\n",
      "Epoch 4/100\n",
      "1073/1073 [==============================] - 10s 9ms/step - loss: 0.8925 - accuracy: 0.8893 - val_loss: 1.0441 - val_accuracy: 0.8415\n",
      "Epoch 5/100\n",
      "1073/1073 [==============================] - 9s 9ms/step - loss: 0.8144 - accuracy: 0.9031 - val_loss: 0.9840 - val_accuracy: 0.8433\n",
      "Epoch 6/100\n",
      "1073/1073 [==============================] - 10s 9ms/step - loss: 0.7551 - accuracy: 0.9132 - val_loss: 0.9544 - val_accuracy: 0.8405\n",
      "Epoch 7/100\n",
      "1073/1073 [==============================] - 10s 9ms/step - loss: 0.7010 - accuracy: 0.9186 - val_loss: 0.9058 - val_accuracy: 0.8497\n",
      "Epoch 8/100\n",
      "1073/1073 [==============================] - 10s 9ms/step - loss: 0.6535 - accuracy: 0.9266 - val_loss: 0.8770 - val_accuracy: 0.8484\n",
      "Epoch 9/100\n",
      "1073/1073 [==============================] - 10s 9ms/step - loss: 0.6097 - accuracy: 0.9314 - val_loss: 0.8385 - val_accuracy: 0.8504\n",
      "Epoch 10/100\n",
      "1073/1073 [==============================] - 10s 9ms/step - loss: 0.5747 - accuracy: 0.9380 - val_loss: 0.8185 - val_accuracy: 0.8506\n",
      "Epoch 11/100\n",
      "1073/1073 [==============================] - 9s 9ms/step - loss: 0.5472 - accuracy: 0.9431 - val_loss: 0.8062 - val_accuracy: 0.8517\n",
      "Epoch 12/100\n",
      "1073/1073 [==============================] - 9s 9ms/step - loss: 0.5219 - accuracy: 0.9441 - val_loss: 0.8055 - val_accuracy: 0.8500\n",
      "Epoch 13/100\n",
      "1073/1073 [==============================] - 10s 9ms/step - loss: 0.4994 - accuracy: 0.9505 - val_loss: 0.7727 - val_accuracy: 0.8522\n",
      "Epoch 14/100\n",
      "1073/1073 [==============================] - 10s 10ms/step - loss: 0.4843 - accuracy: 0.9477 - val_loss: 0.7774 - val_accuracy: 0.8536\n",
      "Epoch 15/100\n",
      "1073/1073 [==============================] - 9s 9ms/step - loss: 0.4685 - accuracy: 0.9526 - val_loss: 0.7559 - val_accuracy: 0.8560\n",
      "Epoch 16/100\n",
      "1073/1073 [==============================] - 9s 9ms/step - loss: 0.4559 - accuracy: 0.9544 - val_loss: 0.7487 - val_accuracy: 0.8534\n",
      "Epoch 17/100\n",
      "1073/1073 [==============================] - 10s 9ms/step - loss: 0.4363 - accuracy: 0.9568 - val_loss: 0.7393 - val_accuracy: 0.8556\n",
      "Epoch 18/100\n",
      "1073/1073 [==============================] - 10s 9ms/step - loss: 0.4357 - accuracy: 0.9585 - val_loss: 0.7502 - val_accuracy: 0.8526\n",
      "Epoch 19/100\n",
      "1073/1073 [==============================] - 10s 9ms/step - loss: 0.4243 - accuracy: 0.9575 - val_loss: 0.7277 - val_accuracy: 0.8568\n",
      "Epoch 20/100\n",
      "1073/1073 [==============================] - 9s 9ms/step - loss: 0.4122 - accuracy: 0.9606 - val_loss: 0.7306 - val_accuracy: 0.8534\n",
      "Epoch 21/100\n",
      "1073/1073 [==============================] - 10s 9ms/step - loss: 0.3986 - accuracy: 0.9610 - val_loss: 0.7326 - val_accuracy: 0.8503\n",
      "Epoch 22/100\n",
      "1073/1073 [==============================] - 10s 9ms/step - loss: 0.3916 - accuracy: 0.9607 - val_loss: 0.7470 - val_accuracy: 0.8479\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_t.toarray(),\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    callbacks=keras.callbacks.EarlyStopping(patience=3, monitor=\"val_loss\"),\n",
    "    batch_size=8,\n",
    "    validation_data=(X_val_t.toarray(), y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------weighted-----------------------------------------------\n",
      "Train f1_score: 0.9784136062986091\n",
      "Val f1_score: 0.850445406869914\n",
      "-----------------------------------------------macro-----------------------------------------------\n",
      "Train f1_score: 0.9717728263554425\n",
      "Val f1_score: 0.8017314411734066\n",
      "-----------------------------------------------micro-----------------------------------------------\n",
      "Train f1_score: 0.978326730365882\n",
      "Val f1_score: 0.8479375436961082\n"
     ]
    }
   ],
   "source": [
    "print(47*'-'+\"weighted\"+47*'-')\n",
    "print(\"Train f1_score:\", f1_score(np.argmax(model.predict(X_train_t), axis=1), y_train, average=\"weighted\"))\n",
    "print(\"Val f1_score:\", f1_score(np.argmax(model.predict(X_val_t), axis=1), y_val, average=\"weighted\"))\n",
    "print(47*'-'+\"macro\"+47*'-')\n",
    "print(\"Train f1_score:\", f1_score(np.argmax(model.predict(X_train_t), axis=1), y_train, average=\"macro\"))\n",
    "print(\"Val f1_score:\", f1_score(np.argmax(model.predict(X_val_t), axis=1), y_val, average=\"macro\"))\n",
    "print(47*'-'+\"micro\"+47*'-')\n",
    "print(\"Train f1_score:\", f1_score(np.argmax(model.predict(X_train_t), axis=1), y_train, average=\"micro\"))\n",
    "print(\"Val f1_score:\", f1_score(np.argmax(model.predict(X_val_t), axis=1), y_val, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 score weighted par classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_score = pd.DataFrame()\n",
    "data_score[\"y_pred\"] = np.argmax(model.predict(X_val_t),axis=1)\n",
    "data_score[\"y_true\"] = y_val.reset_index()[\"cible\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_classe(classe):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8e72ecd218193d245fb3b010d45ad55dac7ff54b5052aa4883c6a911d9d65f6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('rb_ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
