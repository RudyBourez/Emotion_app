{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion = pd.read_csv(\"../Data/emotions_kaggle.csv\")\n",
    "df_augmentation = pd.read_csv(\"../Data/emotions_augmentation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion.rename(columns={\"Text\": \"text\", \"Emotion\": \"target\"}, inplace=True)\n",
    "df_augmentation.rename(columns={\"content\": \"text\", \"sentiment\": \"target\"}, inplace=True)\n",
    "df_augmentation.drop([\"tweet_id\", \"author\"],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target                                               text\n",
       "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2     sadness                Funeral ceremony...gloomy friday...\n",
       "3  enthusiasm               wants to hang out with friends SOON!\n",
       "4     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_augmentation.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nombre d'émotions dans chaque dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion: ['sadness' 'anger' 'love' 'surprise' 'fear' 'happy']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Augmentation: ['empty' 'sadness' 'enthusiasm' 'neutral' 'worry' 'surprise' 'love' 'fun'\n",
      " 'hate' 'happiness' 'boredom' 'relief' 'anger']\n"
     ]
    }
   ],
   "source": [
    "print(\"Emotion:\", df_emotion.target.unique())\n",
    "print(100*'-')\n",
    "print(\"Augmentation:\", df_augmentation.target.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "anger       2993\n",
       "fear        2652\n",
       "happy       7029\n",
       "love        1641\n",
       "sadness     6265\n",
       "surprise     879\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emotion.groupby(\"target\").count()[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "anger          110\n",
       "boredom        179\n",
       "empty          827\n",
       "enthusiasm     759\n",
       "fun           1776\n",
       "happiness     5209\n",
       "hate          1323\n",
       "love          3842\n",
       "neutral       8638\n",
       "relief        1526\n",
       "sadness       5165\n",
       "surprise      2187\n",
       "worry         8459\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_augmentation.groupby(\"target\").count()[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus d'émotions différentes dans le dataframe augmentation. Deux choix:\n",
    "* ajouter uniquement les données avec les mêmes sentiments entre les deux df\n",
    "* ajouter les données avec les mêmes sentiments et rajouter des sentiments supp provenant d'augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valeurs nulles ou manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan emotion:\n",
      " text      0\n",
      "target    0\n",
      "dtype: int64\n",
      "Vide emotion:\n",
      " text      0\n",
      "target    0\n",
      "dtype: int64\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Nan augmentation:\n",
      " target    0\n",
      "text      0\n",
      "dtype: int64\n",
      "Vide augmentation:\n",
      " target    0\n",
      "text      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN emotion:\\n\",df_emotion.isna().sum())\n",
    "print(\"Vide emotion:\\n\",df_emotion[df_emotion[\"text\"]==\"\"].count())\n",
    "print(100*'-')\n",
    "print(\"NaN augmentation:\\n\",df_augmentation.isna().sum())\n",
    "print(\"Vide augmentation:\\n\",df_augmentation[df_augmentation[\"text\"]==\"\"].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple de texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target                                               text\n",
       "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2     sadness                Funeral ceremony...gloomy friday...\n",
       "3  enthusiasm               wants to hang out with friends SOON!\n",
       "4     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_augmentation.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   target\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emotion.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beaucoup de \"I\" dans les textes du dataframe kaggle tandis qu'il y a beaucoup d'abbréviation et de @.. dans le dataframe augmentation (tweet)  \n",
    "Il faudra veiller à traiter les données différemment pour les deux dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texthero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import texthero as hero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augmentation['clean_text'] = hero.clean(df_augmentation['text'])\n",
    "df_emotion['clean_text'] = hero.clean(df_emotion['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target               \n",
       "anger     feel           1803\n",
       "          feeling         923\n",
       "          like            479\n",
       "          im              426\n",
       "          really          171\n",
       "          get             154\n",
       "          people          150\n",
       "          know            149\n",
       "          time            146\n",
       "          little          136\n",
       "fear      feel           1483\n",
       "          feeling         926\n",
       "          im              383\n",
       "          like            323\n",
       "          little          194\n",
       "          bit             143\n",
       "          know            139\n",
       "          really          129\n",
       "          anxious         126\n",
       "          still           119\n",
       "happy     feel           4948\n",
       "          feeling        1956\n",
       "          like           1267\n",
       "          im             1007\n",
       "          really          381\n",
       "          time            370\n",
       "          know            323\n",
       "          get             311\n",
       "          make            276\n",
       "          people          266\n",
       "love      feel           1180\n",
       "          feeling         471\n",
       "          like            393\n",
       "          im              251\n",
       "          love            119\n",
       "          really          112\n",
       "          know            101\n",
       "          sweet            84\n",
       "          time             82\n",
       "          loving           82\n",
       "sadness   feel           4095\n",
       "          feeling        1924\n",
       "          like           1078\n",
       "          im              875\n",
       "          really          352\n",
       "          know            344\n",
       "          get             289\n",
       "          would           273\n",
       "          time            271\n",
       "          little          267\n",
       "surprise  feel            464\n",
       "          feeling         261\n",
       "          like            121\n",
       "          im              113\n",
       "          amazed           83\n",
       "          curious          72\n",
       "          impressed        72\n",
       "          overwhelmed      69\n",
       "          surprised        68\n",
       "          funny            68\n",
       "Name: clean_text, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emotion.groupby('target')['clean_text'].apply(lambda x: hero.top_words(x)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feel, feeling, like, im et know sont des stop words dans ce jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from texthero import stopwords\n",
    "default_stopwords = stopwords.DEFAULT\n",
    "custom_stopwords = default_stopwords.union(set([\"feel\", \"feeling\", \"like\", \"im\", \"know\"]))\n",
    "df_emotion['clean_text'] = hero.remove_stopwords(df_emotion['clean_text'], custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target               \n",
       "anger     really         171\n",
       "          get            154\n",
       "          people         150\n",
       "          time           146\n",
       "          little         136\n",
       "          want           129\n",
       "          even           125\n",
       "          would          118\n",
       "          angry          116\n",
       "          think          111\n",
       "fear      little         194\n",
       "          bit            143\n",
       "          really         129\n",
       "          anxious        126\n",
       "          time           119\n",
       "          still          119\n",
       "          people         106\n",
       "          one            104\n",
       "          nervous        103\n",
       "          get             98\n",
       "happy     really         381\n",
       "          time           370\n",
       "          get            311\n",
       "          make           276\n",
       "          people         266\n",
       "          would          265\n",
       "          one            254\n",
       "          want           250\n",
       "          good           246\n",
       "          something      244\n",
       "love      love           119\n",
       "          really         112\n",
       "          sweet           84\n",
       "          time            82\n",
       "          loving          82\n",
       "          want            80\n",
       "          people          80\n",
       "          caring          78\n",
       "          passionate      75\n",
       "          one             74\n",
       "sadness   really         352\n",
       "          get            289\n",
       "          would          273\n",
       "          time           271\n",
       "          little         267\n",
       "          ive            266\n",
       "          still          243\n",
       "          even           239\n",
       "          want           237\n",
       "          one            230\n",
       "surprise  amazed          83\n",
       "          curious         72\n",
       "          impressed       72\n",
       "          overwhelmed     69\n",
       "          surprised       68\n",
       "          funny           68\n",
       "          weird           67\n",
       "          strange         60\n",
       "          amazing         56\n",
       "          little          56\n",
       "Name: clean_text, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emotion.groupby('target')['clean_text'].apply(lambda x: hero.top_words(x)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8e72ecd218193d245fb3b010d45ad55dac7ff54b5052aa4883c6a911d9d65f6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('rb_ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
